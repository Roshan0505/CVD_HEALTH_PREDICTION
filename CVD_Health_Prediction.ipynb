{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# ğŸ¥ General Health Prediction from CVD Dataset\n",
    "### Elewayte ML Internship Project\n",
    "\n",
    "**Models Used:** SVM Â· Random Forest Â· Logistic Regression  \n",
    "**Target Variable:** `General_Health` (Poor / Fair / Good / Very Good / Excellent)  \n",
    "**Pipeline:** Load â†’ Preprocess â†’ Train (80%) â†’ Test (20%) â†’ Evaluate â†’ Hyperparameter Tuning â†’ Single Input Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-md",
   "metadata": {},
   "source": [
    "## Step 1 â€“ Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Standard imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# â”€â”€ Sklearn preprocessing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# â”€â”€ Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# â”€â”€ Evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print('âœ… All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-md",
   "metadata": {},
   "source": [
    "## Step 2 â€“ Load the Dataset\n",
    "\n",
    "> **Google Colab tip:** Upload the file using the cell below, OR mount Google Drive if the file is stored there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Option A: Upload directly (easiest for beginners) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from google.colab import files\n",
    "uploaded = files.upload()          # A dialog will pop up â€” select CVD_cleaned.csv\n",
    "\n",
    "import io\n",
    "filename = list(uploaded.keys())[0]\n",
    "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
    "\n",
    "# â”€â”€ OR Option B: If file is already in Colab session storage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# df = pd.read_csv('CVD_cleaned.csv')\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-md",
   "metadata": {},
   "source": [
    "## Step 3 â€“ Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print('Shape:', df.shape)\n",
    "print('\\nColumn names:', df.columns.tolist())\n",
    "print('\\nData types:\\n', df.dtypes)\n",
    "print('\\nMissing values:\\n', df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "plt.figure(figsize=(8, 4))\n",
    "order = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "sns.countplot(data=df, x='General_Health', order=order, palette='Set2')\n",
    "plt.title('Distribution of General Health (Target Variable)', fontsize=14)\n",
    "plt.xlabel('General Health')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-md",
   "metadata": {},
   "source": [
    "## Step 4 â€“ Data Preprocessing\n",
    "\n",
    "The dataset has **categorical columns** (like Yes/No, Male/Female, Age ranges).  \n",
    "We convert all of them into **numbers** using Label Encoding â€” a must for ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on a copy so original data is safe\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Identify all categorical (object) columns\n",
    "cat_cols = df_encoded.select_dtypes(include='object').columns.tolist()\n",
    "print('Categorical columns to encode:', cat_cols)\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "le_dict = {}   # Store encoders so we can use them later for single prediction\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "print('\\nâœ… Encoding complete!')\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-md",
   "metadata": {},
   "source": [
    "## Step 5 â€“ Define Features (X) and Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target column: General_Health\n",
    "TARGET = 'General_Health'\n",
    "\n",
    "X = df_encoded.drop(columns=[TARGET])   # All columns except target\n",
    "y = df_encoded[TARGET]                  # Only the target\n",
    "\n",
    "print('Features shape:', X.shape)\n",
    "print('Target shape  :', y.shape)\n",
    "print('Target classes:', le_dict[TARGET].classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6-md",
   "metadata": {},
   "source": [
    "## Step 6 â€“ Train / Test Split (80 : 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,        # 20% for testing\n",
    "    random_state=42,      # Reproducibility\n",
    "    stratify=y            # Keep class balance in both sets\n",
    ")\n",
    "\n",
    "print(f'Training samples : {X_train.shape[0]}')\n",
    "print(f'Testing  samples : {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7-md",
   "metadata": {},
   "source": [
    "## Step 7 â€“ Feature Scaling\n",
    "\n",
    "SVM and Logistic Regression are **sensitive to scale** (e.g., BMI vs Age can confuse them).  \n",
    "We use `StandardScaler` to normalize features. Random Forest doesn't need it, but scaling won't hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scaling",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit ONLY on training data, then transform both sets\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "print('âœ… Scaling done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8-md",
   "metadata": {},
   "source": [
    "## Step 8 â€“ Build & Evaluate All Three Models\n",
    "\n",
    "We train each model on `X_train`, predict on `X_test`, and check:\n",
    "- **Accuracy Score** â€“ % of correct predictions\n",
    "- **Classification Report** â€“ Precision, Recall, F1 per class\n",
    "- **Confusion Matrix** â€“ Visual of correct vs wrong predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lr-md",
   "metadata": {},
   "source": [
    "### 8.1 â€“ Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_sc, y_train)\n",
    "\n",
    "# â”€â”€ Predict â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "lr_pred = lr_model.predict(X_test_sc)\n",
    "\n",
    "# â”€â”€ Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "print(f'Logistic Regression Accuracy: {lr_acc:.4f} ({lr_acc*100:.2f}%)')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, lr_pred, target_names=le_dict[TARGET].classes_))\n",
    "\n",
    "# â”€â”€ Confusion Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, lr_pred,\n",
    "    display_labels=le_dict[TARGET].classes_,\n",
    "    cmap='Blues', ax=ax\n",
    ")\n",
    "ax.set_title('Logistic Regression â€“ Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf-md",
   "metadata": {},
   "source": [
    "### 8.2 â€“ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)   # RF doesn't need scaled data\n",
    "\n",
    "# â”€â”€ Predict â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# â”€â”€ Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "print(f'Random Forest Accuracy: {rf_acc:.4f} ({rf_acc*100:.2f}%)')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, rf_pred, target_names=le_dict[TARGET].classes_))\n",
    "\n",
    "# â”€â”€ Confusion Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, rf_pred,\n",
    "    display_labels=le_dict[TARGET].classes_,\n",
    "    cmap='Greens', ax=ax\n",
    ")\n",
    "ax.set_title('Random Forest â€“ Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svm-md",
   "metadata": {},
   "source": [
    "### 8.3 â€“ Support Vector Machine (SVM)\n",
    "\n",
    "> âš ï¸ SVM is slow on large datasets. We train on a **sample of 30,000 rows** to keep it manageable in Colab. This is a standard practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "svm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for speed (SVM is O(nÂ²) in memory)\n",
    "SAMPLE_SIZE = 30000\n",
    "idx = np.random.choice(len(X_train_sc), size=SAMPLE_SIZE, replace=False)\n",
    "X_train_svm = X_train_sc[idx]\n",
    "y_train_svm = y_train.iloc[idx]\n",
    "\n",
    "# â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# â”€â”€ Predict â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "svm_pred = svm_model.predict(X_test_sc)\n",
    "\n",
    "# â”€â”€ Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "print(f'SVM Accuracy: {svm_acc:.4f} ({svm_acc*100:.2f}%)')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, svm_pred, target_names=le_dict[TARGET].classes_))\n",
    "\n",
    "# â”€â”€ Confusion Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, svm_pred,\n",
    "    display_labels=le_dict[TARGET].classes_,\n",
    "    cmap='Oranges', ax=ax\n",
    ")\n",
    "ax.set_title('SVM â€“ Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step9-md",
   "metadata": {},
   "source": [
    "## Step 9 â€“ Accuracy Comparison Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "barchart",
   "metadata": {},
   "outputs": [],
   "source": [
    "models      = ['Logistic Regression', 'Random Forest', 'SVM']\n",
    "accuracies  = [lr_acc, rf_acc, svm_acc]\n",
    "colors      = ['#4C72B0', '#55A868', '#C44E52']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(models, [a * 100 for a in accuracies], color=colors, width=0.4, edgecolor='black')\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.3,\n",
    "        f'{acc*100:.2f}%',\n",
    "        ha='center', va='bottom', fontsize=12, fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.ylim(0, 110)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Model Accuracy Comparison', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "results_df = pd.DataFrame({'Model': models, 'Accuracy (%)': [round(a*100, 2) for a in accuracies]})\n",
    "print(results_df.to_string(index=False))\n",
    "best = results_df.loc[results_df['Accuracy (%)'].idxmax(), 'Model']\n",
    "print(f'\\nğŸ† Best Model: {best}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step10-md",
   "metadata": {},
   "source": [
    "## Step 10 â€“ Hyperparameter Tuning with Randomized Grid Search\n",
    "\n",
    "We tune the **best performing model** (Random Forest) to squeeze out better accuracy.  \n",
    "`RandomizedSearchCV` tries random combinations of parameters â€” faster than exhaustive grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Define parameter grid â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "param_dist = {\n",
    "    'n_estimators'     : [50, 100, 200, 300],\n",
    "    'max_depth'        : [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf' : [1, 2, 4],\n",
    "    'max_features'     : ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# â”€â”€ Randomized Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "rf_tuned = RandomizedSearchCV(\n",
    "    estimator  = RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_distributions = param_dist,\n",
    "    n_iter     = 10,          # Try 10 random combinations\n",
    "    cv         = 3,           # 3-fold cross-validation\n",
    "    scoring    = 'accuracy',\n",
    "    random_state = 42,\n",
    "    verbose    = 2,\n",
    "    n_jobs     = -1\n",
    ")\n",
    "\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "\n",
    "print('\\nâœ… Best Parameters found:')\n",
    "print(rf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tuned-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned model\n",
    "tuned_pred = rf_tuned.best_estimator_.predict(X_test)\n",
    "tuned_acc  = accuracy_score(y_test, tuned_pred)\n",
    "\n",
    "print(f'Tuned Random Forest Accuracy : {tuned_acc*100:.2f}%')\n",
    "print(f'Original Random Forest Accuracy: {rf_acc*100:.2f}%')\n",
    "print(f'Improvement: {(tuned_acc - rf_acc)*100:+.2f}%')\n",
    "\n",
    "print('\\nClassification Report (Tuned RF):')\n",
    "print(classification_report(y_test, tuned_pred, target_names=le_dict[TARGET].classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step11-md",
   "metadata": {},
   "source": [
    "## Step 11 â€“ Feature Importance (Random Forest)\n",
    "\n",
    "Which features matter most for predicting General Health?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feat-imp",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(\n",
    "    rf_model.feature_importances_,\n",
    "    index=X.columns\n",
    ").sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "importances.plot(kind='barh', color='steelblue', edgecolor='black')\n",
    "plt.title('Feature Importance â€“ Random Forest', fontsize=14)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step12-md",
   "metadata": {},
   "source": [
    "## Step 12 â€“ ğŸ¤– AI System: Single Input Prediction\n",
    "\n",
    "This simulates how a real AI health prediction system works.  \n",
    "We take **one real row** from the dataset and predict its General Health status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-pred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Pick one sample from the original (un-encoded) dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sample_index = 5   # You can change this to any row number\n",
    "sample_raw   = df.iloc[sample_index].to_dict()\n",
    "actual_label = sample_raw[TARGET]\n",
    "\n",
    "print('=== INPUT: Patient Details ===')\n",
    "for key, val in sample_raw.items():\n",
    "    print(f'  {key:<35}: {val}')\n",
    "\n",
    "# â”€â”€ Encode the sample using stored encoders â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sample_encoded = {}\n",
    "for col in df.columns:\n",
    "    if col == TARGET:\n",
    "        continue\n",
    "    val = sample_raw[col]\n",
    "    if col in le_dict:\n",
    "        sample_encoded[col] = le_dict[col].transform([val])[0]\n",
    "    else:\n",
    "        sample_encoded[col] = val\n",
    "\n",
    "# â”€â”€ Convert to DataFrame for prediction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "input_df = pd.DataFrame([sample_encoded])\n",
    "\n",
    "# â”€â”€ Predict using the Best Model (Tuned Random Forest) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "prediction_encoded = rf_tuned.best_estimator_.predict(input_df)[0]\n",
    "prediction_label   = le_dict[TARGET].inverse_transform([prediction_encoded])[0]\n",
    "\n",
    "# â”€â”€ Get prediction probabilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "proba = rf_tuned.best_estimator_.predict_proba(input_df)[0]\n",
    "classes = le_dict[TARGET].classes_\n",
    "\n",
    "print('\\n=== ğŸ¤– AI PREDICTION RESULT ===')\n",
    "print(f'  Predicted General Health : {prediction_label}')\n",
    "print(f'  Actual   General Health  : {actual_label}')\n",
    "print(f'  Match                    : {\"âœ… CORRECT\" if prediction_label == actual_label else \"âŒ INCORRECT\"}')\n",
    "\n",
    "print('\\n=== Confidence Scores ===')\n",
    "for cls, prob in sorted(zip(classes, proba), key=lambda x: -x[1]):\n",
    "    bar = 'â–ˆ' * int(prob * 30)\n",
    "    print(f'  {cls:<12}: {bar} {prob*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step13-md",
   "metadata": {},
   "source": [
    "## Step 13 â€“ Custom Input Prediction (Interactive)\n",
    "\n",
    "Enter your own values to get a health prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-pred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Fill in patient details manually â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Valid values shown for categorical columns\n",
    "\n",
    "custom_input = {\n",
    "    'Checkup'                      : 'Within the past year',   # 'Within the past year', 'Within the past 2 years', '5 or more years ago', 'Never'\n",
    "    'Exercise'                     : 'Yes',                    # 'Yes' or 'No'\n",
    "    'Heart_Disease'                : 'No',                     # 'Yes' or 'No'\n",
    "    'Skin_Cancer'                  : 'No',                     # 'Yes' or 'No'\n",
    "    'Other_Cancer'                 : 'No',                     # 'Yes' or 'No'\n",
    "    'Depression'                   : 'No',                     # 'Yes' or 'No'\n",
    "    'Diabetes'                     : 'No',                     # 'Yes' or 'No'\n",
    "    'Arthritis'                    : 'No',                     # 'Yes' or 'No'\n",
    "    'Sex'                          : 'Female',                 # 'Male' or 'Female'\n",
    "    'Age_Category'                 : '25-29',                  # e.g. '18-24', '25-29', ..., '80+'\n",
    "    'Height_(cm)'                  : 165,\n",
    "    'Weight_(kg)'                  : 60,\n",
    "    'BMI'                          : 22.0,\n",
    "    'Smoking_History'              : 'No',                     # 'Yes' or 'No'\n",
    "    'Alcohol_Consumption'          : 0,\n",
    "    'Fruit_Consumption'            : 20,\n",
    "    'Green_Vegetables_Consumption' : 15,\n",
    "    'FriedPotato_Consumption'      : 5\n",
    "}\n",
    "\n",
    "# â”€â”€ Encode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "custom_encoded = {}\n",
    "for col, val in custom_input.items():\n",
    "    if col in le_dict:\n",
    "        custom_encoded[col] = le_dict[col].transform([val])[0]\n",
    "    else:\n",
    "        custom_encoded[col] = val\n",
    "\n",
    "custom_df = pd.DataFrame([custom_encoded])\n",
    "\n",
    "# â”€â”€ Predict â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "custom_pred_enc   = rf_tuned.best_estimator_.predict(custom_df)[0]\n",
    "custom_pred_label = le_dict[TARGET].inverse_transform([custom_pred_enc])[0]\n",
    "custom_proba      = rf_tuned.best_estimator_.predict_proba(custom_df)[0]\n",
    "\n",
    "print('=== ğŸ¤– AI Health Prediction System ===')\n",
    "print(f'\\nPredicted General Health Status: ğŸ‘‰ {custom_pred_label.upper()}')\n",
    "\n",
    "print('\\nConfidence Breakdown:')\n",
    "for cls, prob in sorted(zip(le_dict[TARGET].classes_, custom_proba), key=lambda x: -x[1]):\n",
    "    bar = 'â–ˆ' * int(prob * 30)\n",
    "    print(f'  {cls:<12}: {bar} {prob*100:.1f}%')"
